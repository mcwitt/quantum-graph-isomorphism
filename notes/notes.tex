%        File: notes.tex
%     Created: Tue Jan 08 11:00 AM 2013 P
% Last Change: Tue Jan 08 11:00 AM 2013 P
%
\input{header.tex}
%\usepackage{hyperref}

\newcommand{\nnsum}[2]{\sum_{\langle #1 #2 \rangle}}
\newcommand{\cc}{\mathrm{c.c.}}
\newcommand{\nghbr}[2]{#1,\,#2}

\begin{document}

\section*{Definitions}

\begin{equation}
  H = (1 - s) H_D + s H_P,
  \qquad
  0 \leq s \leq 1
  \label{def-h_qaa}
\end{equation}
\begin{equation}
  H_D = \sum_i \sigma^x_i
  \label{def-h_d}
\end{equation}
\begin{equation}
  H_P = \nnsum{i}{j} \sigma^z_i \sigma^z_j + \sum_i h_i \sigma^z_i,
  \qquad
  h_i \rightarrow h
  \label{def-h_p}
\end{equation}
\begin{equation}
  f_{ij} = \pd{}{h_j} \avg{\sigma^z_i}
  \sim \avg{\sigma^z_i \sigma^z_j}
  \label{def-f}
\end{equation}

Can approximate derivative using finite differences. (Peter's method for
calculating susceptibility using Lanczos?)

\section*{Perturbation theory for susceptibility}

Calculate $f_{ij}$ in first-order nondegenerate perturbation theory.

Let $\ket{\psi}$ be the ground state.
\begin{equation}
  \pd{}{h_j} \avg{\sigma_i}
  = \matrixel{\pd{\psi}{h_j}}{\sigma_i}{\psi} + \cc
  \label{}
\end{equation}
Let
$h_j \rightarrow h_j + \delta h_j$.
Then
$H_P \rightarrow H_P + \delta h_j \sigma_j$.
The first-order change in the ground state is
\begin{equation}
  \ket{\psi^{(1)}}
  = \delta h_j \sum_{n>0} \frac{\matrixel{n}{\sigma_j}{\psi}}{E_0 - E_n} \ket{n}.
  \label{}
\end{equation}
Therefore
\begin{align}
  \ket{\pd{\psi}{h_j}}
  &= \lim_{\delta h_j \rightarrow 0} \frac{1}{\delta h_j} \ket{\psi^{(1)}} \\
  &= \sum_{n>0} \frac{\matrixel{n}{\sigma_j}{\psi}}{E_0 - E_n} \ket{n}
  \label{}
\end{align}
and
\begin{equation}
  \pd{}{h_j} \avg{\sigma_i}
  = -2 \avg{\sigma_j \sum_{n>0} \frac{\ket{n} \bra{n}}{E_n - E_0} \sigma_i}
  \label{}
\end{equation}
where $\avg{\cdots}$ is the ground-state expectation value.

\begin{equation}
  H = \sum_n E_n \ket{n} \bra{n}
  \label{}
\end{equation}
Let
\begin{equation}
  \boxed{
  H^{\prime} \equiv H - E_0 \ket{\psi} \bra{\psi}
  }
  \label{}
\end{equation}
Then
\begin{equation}
  H^{\prime} - E_0 = \sum_{n>0} \left( E_n - E_0 \right) \ket{n} \bra{n}
  \label{}
\end{equation}
and
\begin{equation}
  \boxed{
  \pd{}{h_j} \avg{\sigma_i}
  = -2 \avg{\sigma_j \left( H^{\prime} - E_0 \right)^{-1} \sigma_i}
  }
  \label{}
\end{equation}

\section*{Energy}
\begin{equation}
  H = (1 - s) \avg{H_D} + s \avg{H_P}
  \label{}
\end{equation}
Expand the ground state $\ket{\psi}$ in an orthonormal basis
\begin{equation}
  \ket{\psi} = \sum_{n=0}^{2^N-1} c_n \ket{n},
  \qquad
  \sum_n \abs{c_n}^2 = 1
  \label{}
\end{equation}
where $\ket{n}$ is an eigenstate of
$\sigma_1 \otimes \sigma_2 \otimes \cdots \otimes \sigma_N$
such that
\begin{equation}
    \sum_{k=0}^N \left( \sigma_k + \frac{1}{2} \right) 2^k \ket{n} = n \ket{n}.
  \label{}
\end{equation}
i.e. $\ket{n}$ corresponds to the spin configuration obtained by taking 1
as spin up and 0 as spin down in the binary representation of $n$.
For example, with $N=3$,
\begin{align*}
  \ket{0} \equiv \ket{000}
  &\equiv
  \ket{\downarrow} \otimes
  \ket{\downarrow} \otimes
  \ket{\downarrow} \\
  \ket{1} \equiv \ket{001}
  &\equiv
  \ket{\downarrow} \otimes
  \ket{\downarrow} \otimes
  \ket{\uparrow} \\
  &\vdots \\
  \ket{7} \equiv \ket{111}
  &\equiv
  \ket{\uparrow} \otimes
  \ket{\uparrow} \otimes
  \ket{\uparrow}.
  \label{}
\end{align*}
Because $H$ is real and symmetric in this basis, we can restrict the
coefficients $c_n$ to be real
\begin{equation}
  c_n = c_n^*.
  \label{}
\end{equation}
The driver Hamiltonian $H_D$ connects states that differ by a single spin flip:
\begin{equation}
  \matrixel{n}{H_D}{m}
  = \begin{cases}
    1 & \ket{n}, \ket{m} \text{ differ by a single spin flip} \\
    0
  \end{cases}
  \label{}
\end{equation}
For each state $\ket{n}$ there are $N$ ``neighboring'' states that differ by a
single spin flip. Let $\ket{\nghbr{n}{k}}$ denote the $k$th neighbor of
$\ket{n}$, so that
\begin{align}
  \matrixel{n}{H_D}{\psi}
  &= \sum_m \matrixel{n}{H_D}{m} \braket{m}{\psi} \\
  &= \sum_{k=1}^N \matrixel{n}{H_D}{\nghbr{n}{k}} \braket{\nghbr{n}{k}}{\psi} \\
  &= \sum_{k=1}^N \braket{\nghbr{n}{k}}{\psi}.
  \label{}
\end{align}
Then
\begin{align}
  \avg{H_D}
  &= \sum_n \braket{\psi}{n} \matrixel{n}{H_D}{\psi} \\
  &= \sum_n \braket{\psi}{n} \sum_{k=1}^{N} \braket{\nghbr{n}{k}}{\psi}.
  \label{}
\end{align}
$\avg{H_D}$ can be computed in $N \times 2^N$ steps.
\begin{equation}
  \boxed{
    \avg{H_D} = \sum_n c_n \sum_{k=1}^N c_{(\nghbr{n}{k})}
  }
  \label{}
\end{equation}
The problem Hamiltonian $H_P$ is diagonal in the computational basis. Let
\begin{equation}
  \matrixel{n}{H_P}{n} \equiv E_n.
  \label{}
\end{equation}
Then
\begin{equation}
  \avg{H_P}
  = \sum_{n,\,m} \braket{\psi}{n} \matrixel{n}{H_P}{m} \braket{m}{\psi}
  = \sum_n c_n^2 E_n.
  \label{}
\end{equation}
The function to be minimized is
\begin{equation}
  \boxed{
  E( \{ c_i \})
  \equiv \avg{H}
  = \frac{(1-s) \avg{H_D} + s \avg{H_P}}{\braket{\psi}{\psi}}
  }
  \label{}
\end{equation}
\section*{Gradient of energy}
\begin{equation}
  \pd{E}{c_i} = \frac{1}{\braket{\psi}{\psi}}
  \left[ (1-s) \pd{\avg{H_D}}{c_i} + s \pd{\avg{H_P}}{c_i}
  - E \pd{\braket{\psi}{\psi}}{c_i} \right]
  \label{}
\end{equation}
We now compute the gradient of $H_D$:
\begin{align}
  \pd{\avg{H_D}}{c_i}
  &= \sum_{n,\,m} c_n \matrixel{n}{H_D}{m} c_m \\
  &= \sum_n \left( \matrixel{i}{H_D}{n} c_n + c_n \matrixel{n}{H_D}{i} \right) \\
  &= 2 \matrixel{i}{H_D}{\psi}.
  \label{}
\end{align}
Let
\begin{equation}
  d_i
  \equiv \matrixel{i}{H_D}{\psi}
  = \sum_{k=1}^N \braket{\nghbr{i}{k}}{\psi}
  \label{}
\end{equation}
Then
\begin{equation}
  \boxed{
    \pd{E}{c_i} = \frac{2}{c^2} \left[ (1-s) d_i + s c_i E_i - E c_i \right]
  }
  \label{}
\end{equation}
where
\begin{equation}
  \boxed{
    E = \frac{1}{c^2} \left[ (1-s) \sum_n c_n d_n + s \sum_n c_n^2 E_n \right]
  }
  \label{}
\end{equation}
This computation requires $N \times 2^N$ steps.

\end{document}

